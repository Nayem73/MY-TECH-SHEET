1. <u>RSI-CB: A Large-Scale Remote Sensing Image
   Classification Benchmark Using Crowdsourced Data</u>

link: sensors-20-01594-v2.pdf

Abstract: Image classification is a fundamental task in remote sensing image processing. In recent years, deep convolutional neural networks (DCNNs) have experienced significant breakthroughs in natural image recognition. The remote sensing field, however, is still lacking a large-scale benchmark similar to ImageNet. In this paper, we propose a remote sensing image classification benchmark (RSI-CB) based on massive, scalable, and diverse crowdsourced data. Using crowdsourced data, such as Open Street Map (OSM) data, ground objects in remote sensing images can be annotated effectively using points of interest, vector data from OSM, or other crowdsourced data. These annotated images can, then, be used in remote sensing image classification tasks. Based on this method, we construct a worldwide large-scale benchmark for remote sensing image classification. This benchmark has large-scale geographical distribution and large total image number. It contains six categories with 35 sub-classes of more than 24,000 images of size 256 × 256 pixels. This classification system of ground objects is defined according to the national standard of land-use classification in China and is inspired by the hierarchy mechanism of ImageNet. Finally, we conduct numerous experiments to compare RSI-CB with the SAT-4, SAT-6, and UC-Merced data sets. The experiments show that RSI-CB is more suitable as a benchmark for remote sensing image classification tasks than other benchmarks in the big data era and has many potential applications.



2. Land Use Classification using Convolutional Neural
   Networks Applied to Ground-Level Images

link: Zhu_SIGSPATIAL15_LandUseClassification.pdf

ABSTRACT
Land use mapping is a fundamental yet challenging task in
geographic science. In contrast to land cover mapping, it is
generally not possible using overhead imagery. The recent,
explosive growth of online geo-referenced photo collections
suggests an alternate approach to geographic knowledge discovery. In this work, we present a general framework that
uses ground-level images from Flickr for land use mapping.
Our approach benefits from several novel aspects. First,
we address the nosiness of the online photo collections, such
as imprecise geolocation and uneven spatial distribution, by
performing location and indoor/outdoor filtering, and semisupervised dataset augmentation. Our indoor/outdoor classifier achieves state-of-the-art performance on several benchmark datasets and approaches human-level accuracy. Second, we utilize high-level semantic image features extracted
using deep learning, specifically convolutional neural networks, which allow us to achieve upwards of 76% accuracy
on a challenging eight class land use mapping problem.



3. # Remote Sensing Signature Classification of Agriculture Detection Using Deep Convolution Network Models

link: https://link.springer.com/chapter/10.1007/978-981-15-6315-7_28[Remote Sensing Signature Classification of Agriculture Detection Using Deep Convolution Network Models | SpringerLink](https://link.springer.com/chapter/10.1007/978-981-15-6315-7_28)

## Abstract

Categorical signature classification plays a vital role in environmental monitoring, disaster response, etc. In view of Geographical expansions, manual identification of the object is time consuming and task of classification is difficult owing to limited trained images. Conventional categorical signature classification using Machine learning techniques requires higher level of abstract features. Deep learning is a successful technique that is widely used in extracting minute level multiple features of the object representation for automatic learning of the data representation. In this paper, performance analysis of the state of the art eight pre trained Convolutional Neural Networks (CNN) networks (Alexnet, Resnet34, Resnet 50, Resnet-101 Resnet-152, VGG-16, VGG-19 and Densenet-121) are tested for the benchmarked datasets (UC Merced and EUROSAT Datasets). Common signature between the datasets like Agriculture, Residential, River and salt lake is considered with the objective of search of the agriculture in an area composed of residential, river and lake. It is concluded from the results that the use of more number of images to train for the search of particular dataset and the use of shallow CNN network increase the accuracy, precision, recall and F-Score, closer to unity (one). Densenet-121 performs better when compared to other CNN networks for both the datasets with an accuracy of 99.67% (EUROSAT) and 97.05% (UC Merced) respectively. Hence, Densenet-121 is recommended for the search of the particular object in a remote sensed scene and classification into respective labels.



4. UC-Merced Image Classification with CNN Feature Reduction Using Wavelet Entropy Optimized with Genetic Algorithm

link: [UC-Merced Image Classification with CNN Feature Reduction Using Wavelet Entropy Optimized with Genetic Algorithm | IIETA](https://www.iieta.org/journals/ts/paper/10.18280/ts.370301)

Abstract: 

The classification of high-resolution and remote sensed terrain images with high accuracy is one of the greatest challenges in machine learning. In the present study, a novel CNN feature reduction using Wavelet Entropy Optimized with Genetic Algorithm (GA-WEE-CNN) method was used for remote sensing images classification. The optimal wavelet family and optimal value of the parameters of the Wavelet Sure Entropy (WSE), Wavelet Norm Entropy (WNE), and Wavelet Threshold Entropy (WTE) were calculated, and given to classifiers such as K-Nearest Neighbors (KNN) and Support Vector Machine (SVM). The efficiency of the proposed hybrid method was tested using the UC-Merced dataset. 80% of the data were used as training data, and a performance rate of 98.8% was achieved with SVM classifier, which has been the highest ratio compared to all studies using same dataset so far with only 18 features. These results proved the advantage of the proposed method.



5. ### [Utilization of deep convolutional neural networks for remote sensing scenes classification](https://books.google.com/books?hl=en&lr=&id=8pj8DwAAQBAJ&oi=fnd&pg=PA67&dq=Luo,+C.,+et+al.:+Utilisation+of+deep+convolutional+neural+networks+for+remote+sensing+scenes+classification.+In:+Advanced+Remote+Sensing+Technology+for+Synthetic+Aperture+Radar+Applications,+Tsunami+Disasters+and+Infrastructure.+Intech+Open,+London+(2018).+Intech+open-open+access+peer+reviewed+chapter&ots=4xrTcri9Vn&sig=9l8eCe9PzIWubhOyrRJZKHYCoMM)

Abstract

Deep convolutional neural networks (CNNs) have been widely used to obtain high-level representation in various computer vision tasks. However, for the task of remote scene classification, there are no sufficient images to train a very deep CNN from scratch. Instead, transferring successful pre-trained deep CNNs to remote sensing tasks provides an effective solution. Firstly, from the viewpoint of generalization power, we try to find whether deep CNNs need to be deep when applied for remote scene classification. Then, the pre-trained deep CNNs with fixed parameters are transferred for remote scene classification, which solve the problem of timeconsuming and parameters over-fitting at the same time. With five well-known pre-trained deep CNNs, experimental results on three independent remote sensing datasets demonstrate that transferred deep CNNs can achieve state-of-the-art results in unsupervised setting. This chapter also provides baseline for applying deep CNNs to other remote sensing tasks.



6. ### [Building detection in very high resolution multispectral data with deep learning features](https://ieeexplore.ieee.org/abstract/document/7326158/)

The automated man-made object detection and building extraction from single satellite images is, still, one of the most challenging tasks for various urban planning and monitoring engineering applications. To this end, in this paper we propose an automated building detection framework from very high resolution remote sensing data based on deep convolutional neural networks. The core of the developed method is based on a supervised classification procedure employing a very large training dataset. An MRF model is then responsible for obtaining the optimal labels regarding the detection of scene buildings. The experimental results and the performed quantitative validation indicate the quite promising potentials of the developed approach.



7. ### [Analysis of the inter-dataset representation ability of deep features for high spatial resolution remote sensing image scene classification](https://link.springer.com/article/10.1007/s11042-018-6548-6)

Abstract

Recently, scene based classification has become a new trend for very high spatial resolution remote sensing image interpretation. With the advent of deep learning, the pretrained convolutional neural networks (CNNs) have been proved effective as feature extractors for scene classification tasks in the remote sensing domain, but the potential characteristics and capabilities of such deep features have not been sufficiently analyzed and fully understood. Facing with complex remote sensing scenes with huge intra-class variations, it is still not clear about the limitation of these powerful deep features in exploring essential invariant attributes of remote sensing scenes of the same kind but, in most cases, from separate sources. Therefore, this paper makes an intensive investigation in the feature representation ability of such deep features from the aspect of inter-dataset scene classification of remote sensing images. Four well-known pretrained CNN models and three different commonly used datasets are selected and summarized. Firstly, deep features extracted from various intermediate layers of these models are compared. Then, the inter-dataset feature representation ability is evaluated using cross-classification of different datasets and discussed in terms of imaging spatial resolution, image size, model structure, and time efficiency. Finally, several instructive findings are revealed and conclusions are drawn regarding the strength and weakness of the CNN features in the application of remote sensing image scene classification.



8. ### [Research on high resolution remote sensing image classification based on convolution neural network](https://link.springer.com/chapter/10.1007/978-3-030-06137-1_9)

Abstract

Traditional classification method based on machine learning algorithm has been widely adopted in very high resolution remote sensing image classification, yet the problem that could not effectively convey a higher level of abstract feature still need to be improved. This paper, relying on the convolution neural network algorithm, has conducted on the high-resolution remote sensing image classification method. Firstly, structure of convolution neural networks was analyzed. The prediction model of convolution neural networks was discussed, and the core of structure was the alternation of the convolution layer and the down sampling layer. Then, the training model of convolution neural networks was researched. By using weights sharing and local connection, convolution neural network, that image could directly entered into, avoids to a certain extent caused by image displacement, dimension change and so on. On this basis, basing on different phase GF-1 remote sensing data and MATLAB development environment under Windows10 operating system, then combining with object-oriented classification technology in image segmentation, this paper built the high resolution remote sensing image classification model based on convolution neural network. Finally, the parameters of the model were tested and analyzed repeatedly, and more accurate model parameters were obtained in this paper. Results show that the mode can effectively improve the classification accuracy, and provide technical support for improving remote sensing image interpretation and formulating sustainable development strategy.



9. ### [**Satellite image classification** with **deep learning**](https://ieeexplore.ieee.org/abstract/document/8457969/)

Satellite imagery is important for many applications including disaster response, law enforcement, and environmental monitoring. These applications require the manual identification of objects and facilities in the imagery. Because the geographic expanses to be covered are great and the analysts available to conduct the searches are few, automation is required. Yet traditional object detection and classification algorithms are too inaccurate and unreliable to solve the problem. Deep learning is a family of machine learning algorithms that have shown promise for the automation of such tasks. It has achieved success in image understanding by means of convolutional neural networks. In this paper we apply them to the problem of object and facility recognition in high-resolution, multi-spectral satellite imagery. We describe a deep learning system for classifying objects and facilities from the IARPA Functional Map of the World (fMoW) dataset into 63 different classes. The system consists of an ensemble of convolutional neural networks and additional neural networks that integrate satellite metadata with image features. It is implemented in Python using the Keras and TensorFlow deep learning libraries and runs on a Linux server with an NVIDIA Titan X graphics card. At the time of writing the system is in 2nd place in the fMoW TopCoder competition. Its total accuracy is 83%, the F 1 score is 0.797, and it classifies 15 of the classes with accuracies of 95% or better.
